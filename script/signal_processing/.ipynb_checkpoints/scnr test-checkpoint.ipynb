{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import pyroomacoustics as pra\n",
    "import matplotlib.pyplot as plt\n",
    "from pyroomacoustics.denoise import SpectralSub\n",
    "from scipy import integrate\n",
    "import signal_generator\n",
    "\"\"\"\n",
    "Test and algorithm parameters\n",
    "\"\"\"\n",
    "snr = 5         # SNR of input signal.\n",
    "db_reduc = 10   # Maximum suppression per frequency bin. Large suppresion can result in more musical noise.\n",
    "nfft = 512      # Frame length will be nfft/2 as we will use an STFT with 50% overlap.\n",
    "lookback = 12   # How many frames to look back for the noise floor estimate.\n",
    "beta = 3        # An overestimation factor to \"push\" the suppression towards db_reduc.\n",
    "alpha = 1.2     # An exponential factor to tune the suppresion (see documentation of 'SpectralSub').\n",
    "\n",
    "plot_spec = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare input file\n",
    "\"\"\"\n",
    "signal_fp = '/Users/axel/KWS/audio/experiment/Alexa_P09_05.wav'\n",
    "noise_fp = '/Users/axel/KWS/audio/speech_dataset_v0_01/_background_noise_/pink_noise.wav'\n",
    "generated_fp = '/Users/axel/KWS/audio/experiment/Alexa_P09_05_noised.wav'\n",
    "filtered_fp = '/Users/axel/KWS/audio/experiment/Alexa_P09_05_filtered.wav'\n",
    "filtered_iw_fp = '/Users/axel/KWS/audio/experiment/Alexa_P09_05_filtered_iw.wav'\n",
    "\n",
    "noisy_signal, signal, noise, fs = signal_generator.create_noisy_signal(signal_fp,\n",
    "                                                          snr=snr,\n",
    "                                                          noise_fp=noise_fp)\n",
    "wavfile.write(generated_fp, fs, noisy_signal.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_spectral_sub(noisy_signal, nfft=128, db_reduc=15, lookback=24,\n",
    "                       beta=30, alpha=1):\n",
    "    \"\"\"\n",
    "    One-shot function to apply spectral subtraction approach.\n",
    "    Parameters\n",
    "    ----------\n",
    "    noisy_signal : numpy array\n",
    "        Real signal in time domain.\n",
    "    nfft: int\n",
    "        FFT size. Length of gain filter, i.e. the number of frequency bins, is\n",
    "        given by ``nfft//2+1``.\n",
    "    db_reduc: float\n",
    "        Maximum reduction in dB for each bin.\n",
    "    lookback: int\n",
    "        How many frames to look back for the noise estimate.\n",
    "    beta: float\n",
    "        Overestimation factor to \"push\" the gain filter value (at each\n",
    "        frequency) closer to the dB reduction specified by ``db_reduc``.\n",
    "    alpha: float, optional\n",
    "        Exponent factor to modify transition behavior towards the dB reduction\n",
    "        specified by ``db_reduc``. Default is 1.\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array\n",
    "        Enhanced/denoised signal.\n",
    "    \"\"\"\n",
    "\n",
    "    from pyroomacoustics import hann\n",
    "    from pyroomacoustics.transform import STFT\n",
    "\n",
    "    hop = nfft // 2\n",
    "    window = hann(nfft, flag='asymmetric', length='full')\n",
    "    stft = STFT(nfft, hop=hop, analysis_window=window, streaming=True)\n",
    "    scnr = SpectralSub(nfft, db_reduc, lookback, beta, alpha)\n",
    "\n",
    "    processed_audio = np.zeros(noisy_signal.shape)\n",
    "    n = 0\n",
    "    while noisy_signal.shape[0] - n >= hop:\n",
    "        # SCNR in frequency domain\n",
    "        stft.analysis(noisy_signal[n:(n + hop), ])\n",
    "        gain_filt = scnr.compute_gain_filter(stft.X)\n",
    "\n",
    "        # back to time domain\n",
    "        processed_audio[n:n + hop, ] = stft.synthesis(gain_filt * stft.X)\n",
    "\n",
    "        # update step\n",
    "        n += hop\n",
    "\n",
    "    return processed_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeWiener(object):\n",
    "    \"\"\"\n",
    "    A class for performing **single channel** noise reduction in the frequency\n",
    "    domain with a Wiener filter that is iteratively computed. This\n",
    "    implementation is based off of the approach presented in:\n",
    "        J. Lim and A. Oppenheim, *All-Pole Modeling of Degraded Speech,*\n",
    "        IEEE Transactions on Acoustics, Speech, and Signal Processing 26.3\n",
    "        (1978): 197-210.\n",
    "    For each frame, a Wiener filter of the following form is computed and\n",
    "    applied to the noisy samples in the frequency domain:\n",
    "    .. math::\n",
    "        H(\\\\omega) = \\dfrac{P_S(\\\\omega)}{P_S(\\\\omega) + \\\\sigma_d^2},\n",
    "    where :math:`P_S(\\omega)` is the speech power spectral density and\n",
    "    :math:`\\sigma_d^2` is the noise variance.\n",
    "    The following assumptions are made in order to arrive at the above filter\n",
    "    as the optimal solution:\n",
    "    - The noisy samples :math:`y[n]` can be written as:\n",
    "      .. math::\n",
    "        y[n] = s[n] + d[n],\n",
    "      where :math:`s[n]` is the desired signal and :math:`d[n]` is the\n",
    "      background noise.\n",
    "    - The signal and noise are uncorrelated.\n",
    "    - The noise is white Gaussian, i.e. it has a flat power spectrum with\n",
    "      amplitude :math:`\\sigma_d^2`.\n",
    "    Under these assumptions, the above Wiener filter minimizes the mean-square\n",
    "    error between the true samples :math:`s[0:N-1]` and the estimated one\n",
    "    :math:`\\hat{s[0:N-1]}` by filtering :math:`y[0:N-1]` with the above filter\n",
    "    (with :math:`N` being the frame length).\n",
    "    The fundamental part of this approach is correctly (or as well as possible)\n",
    "    estimating the speech power spectral density :math:`P_S(\\omega)` and the\n",
    "    noise variance :math:`\\sigma_d^2`. For this, we need a **voice activity\n",
    "    detector** in order to determine when we have incoming speech. In this\n",
    "    implementation, we use a simple energy threshold on the input frame, which\n",
    "    is set with the `thresh` input parameter.\n",
    "    **When no speech is identified**, the input frame is used to update the\n",
    "    noise variance :math:`\\sigma_d^2`. We could simply set :math:`\\sigma_d^2`\n",
    "    to the energy of the input frame. However, we employ a simple IIR filter in\n",
    "    order to avoid abrupt changes in the noise level (thus adding an assumption\n",
    "    of stationary):\n",
    "    .. math::\n",
    "        \\sigma_d^2[k] = \\\\alpha \\cdot \\sigma_d^2[k-1] + (1-\\\\alpha) \\cdot \\sigma_y^2,\n",
    "    where :math:`\\\\alpha` is the smoothing parameter and :math:`\\sigma_y^2` is\n",
    "    the energy of the input frame. A high value of :math:`\\\\alpha` will update\n",
    "    the noise level very slowly, while a low value will make it very sensitive\n",
    "    to changes at the input. The value for :math:`\\\\alpha` can be set with the\n",
    "    `alpha` parameter.\n",
    "    **When speech is identified in the input frame**, an iterative procedure is\n",
    "    employed in order to estimate :math:`P_S(\\omega)` (and therefore the Wiener\n",
    "    filter :math:`H` as well). This procedure consists of computing :math:`p`\n",
    "    `linear predictive coding (LPC) coefficients <https://en.wikipedia.org/wiki/Linear_predictive_coding>`_\n",
    "    of the input frame. The number of LPC coefficients is set with the\n",
    "    parameter `lpc_order`. These LPC coefficients form an all-pole filter that\n",
    "    models the vocal tract as described in the above paper (Eq. 1). With these\n",
    "    coefficients, we can then obtain an estimate of the speech power spectral\n",
    "    density (Eq. 41b) and thus the corresponding Wiener filter (Eq. 41a). This\n",
    "    Wiener filter is used to denoise the input frame. Moreover, with this\n",
    "    denoised frame, we can compute new LPC coefficients and therefore a new\n",
    "    Wiener filter. The idea behind this approach is that by iteratively\n",
    "    computing the LPC coefficients as such, we can obtain a better estimate of\n",
    "    the speech power spectral density. The number of iterations can be set with\n",
    "    the `iterations` parameter.\n",
    "    Below is an example of how to use this class to emulate a streaming/online\n",
    "    input. A full example can be found\n",
    "    `here <https://github.com/LCAV/pyroomacoustics/blob/master/examples/noise_reduction_wiener_filtering.py>`_.\n",
    "    ::\n",
    "        # initialize STFT and IterativeWiener objects\n",
    "        nfft = 512\n",
    "        stft = pra.transform.STFT(nfft, hop=nfft//2,\n",
    "                                  analysis_window=pra.hann(nfft))\n",
    "        scnr = IterativeWiener(frame_len=nfft, lpc_order=20, iterations=2,\n",
    "                               alpha=0.8, thresh=0.01)\n",
    "        # apply block-by-block\n",
    "        for n in range(num_blocks):\n",
    "            # go to frequency domain, 50% overlap\n",
    "            stft.analysis(mono_noisy)\n",
    "            # compute wiener output\n",
    "            X = scnr.compute_filtered_output(\n",
    "                    current_frame=stft.fft_in_buffer,\n",
    "                    frame_dft=stft.X)\n",
    "            # back to time domain\n",
    "            mono_denoised = stft.synthesis(X)\n",
    "    There also exists a \"one-shot\" function.\n",
    "    ::\n",
    "        # import or create `noisy_signal`\n",
    "        denoised_signal = apply_iterative_wiener(noisy_signal, frame_len=512,\n",
    "                                                 lpc_order=20, iterations=2,\n",
    "                                                 alpha=0.8, thresh=0.01)\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame_len : int\n",
    "        Frame length in samples.\n",
    "    lpc_order : int\n",
    "        Number of LPC coefficients to compute\n",
    "    iterations : int\n",
    "        How many iterations to perform in updating the Wiener filter for each\n",
    "        signal frame.\n",
    "    alpha : int\n",
    "        Smoothing factor within [0,1] for updating noise level. Closer to `1`\n",
    "        gives more weight to the previous noise level, while closer to `0`\n",
    "        gives more weight to the current frame's level. Closer to `0` can track\n",
    "        more rapid changes in the noise level. However, if a speech frame is\n",
    "        incorrectly identified as noise, you can end up removing desired\n",
    "        speech.\n",
    "    thresh : float\n",
    "        Threshold to distinguish between (signal+noise) and (noise) frames. A\n",
    "        high value will classify more frames as noise but might remove desired\n",
    "        signal!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, frame_len, lpc_order, iterations, alpha=0.8,\n",
    "                 thresh=0.01):\n",
    "\n",
    "        if frame_len % 2:\n",
    "            raise ValueError(\"Frame length should be even as this method \"\n",
    "                             \"relies on 50% overlap.\")\n",
    "\n",
    "        if (alpha > 1) or (alpha < 0):\n",
    "            raise ValueError(\"`alpha` parameter should be within [0,1].\")\n",
    "\n",
    "        self.frame_len = frame_len\n",
    "        self.hop = frame_len // 2\n",
    "        self.lpc_order = lpc_order\n",
    "        self.iterations = iterations\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # simple energy-based voice activity detector\n",
    "        self.thresh = thresh\n",
    "\n",
    "        # initialize power spectral densities\n",
    "        self.speech_psd = np.ones(self.hop+1)\n",
    "        self.noise_psd = 0\n",
    "        self.wiener_filt = np.ones(self.hop+1)\n",
    "\n",
    "    def compute_filtered_output(self, current_frame, frame_dft=None):\n",
    "        \"\"\"\n",
    "        Compute Wiener filter in the frequency domain.\n",
    "        Parameters\n",
    "        ----------\n",
    "        current_frame : numpy array\n",
    "            Noisy samples.\n",
    "        frame_dft : numpy array\n",
    "            DFT of input samples. If not provided, it will be computed.\n",
    "        Returns\n",
    "        -------\n",
    "        numpy array\n",
    "            Output of denoising in the frequency domain.\n",
    "        \"\"\"\n",
    "\n",
    "        if frame_dft is None:\n",
    "            frame_dft = np.fft.rfft(current_frame)\n",
    "        frame_dft /= np.sqrt(self.frame_len)\n",
    "\n",
    "        frame_energy = np.std(current_frame)**2\n",
    "\n",
    "        # simple VAD\n",
    "        if frame_energy < self.thresh:    # noise frame\n",
    "\n",
    "            # update noise power spectral density\n",
    "            # assuming white noise, i.e. flat spectrum\n",
    "            self.noise_psd = self.alpha * self.noise_psd +\\\n",
    "                             (1 - self.alpha) * frame_energy\n",
    "\n",
    "            # update wiener filter\n",
    "            self.wiener_filt[:] = compute_wiener_filter(self.speech_psd,\n",
    "                                                        self.noise_psd)\n",
    "        else:   # speech frame\n",
    "\n",
    "            s_i = current_frame\n",
    "\n",
    "            # iteratively update speech power spectral density / wiener filter\n",
    "            for i in range(self.iterations):\n",
    "                a = lpc(s_i, self.lpc_order)\n",
    "                g2 = compute_squared_gain(a, self.noise_psd, current_frame)\n",
    "                self.speech_psd[:] = compute_speech_psd(a, g2, self.frame_len)\n",
    "\n",
    "                # update Wiener filter\n",
    "                self.wiener_filt[:] = compute_wiener_filter(self.speech_psd,\n",
    "                                                            self.noise_psd)\n",
    "                # update current frame with denoised version\n",
    "                s_i = np.fft.irfft(self.wiener_filt * frame_dft)\n",
    "\n",
    "        return self.wiener_filt * frame_dft\n",
    "\n",
    "\n",
    "def compute_speech_psd(a, g2, nfft):\n",
    "    \"\"\"\n",
    "    Compute power spectral density of speech as specified in equation (41b) of\n",
    "        J. Lim and A. Oppenheim, *All-Pole Modeling of Degraded Speech,*\n",
    "        IEEE Transactions on Acoustics, Speech, and Signal Processing 26.3\n",
    "        (1978): 197-210.\n",
    "    Namely:\n",
    "    .. math::\n",
    "        P_S(\\\\omega) = \\dfrac{g^2}{\\\\left \\| 1 - \\sum_{k=1}^p a_k \\cdot e^{-jk\\omega} \\\\right \\|^2},\n",
    "    where :math:`p` is the LPC order, :math:`a_k` are the LPC coefficients, and\n",
    "    :math:`g` is an estimated gain factor.\n",
    "    The power spectral density is computed at the frequencies corresponding to\n",
    "    a DFT of length `nfft`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : numpy array\n",
    "        LPC coefficients.\n",
    "    g2 : float\n",
    "        Squared gain.\n",
    "    nfft : int\n",
    "        FFT length.\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array\n",
    "        Power spectral density from LPC coefficients.\n",
    "    \"\"\"\n",
    "    A = np.fft.rfft(np.r_[np.ones(1), -1*a], nfft)\n",
    "    return g2 / np.abs(A)**2\n",
    "\n",
    "\n",
    "def compute_squared_gain(a, noise_psd, y):\n",
    "    \"\"\"\n",
    "    Estimate the squared gain of the speech power spectral density as done on\n",
    "    p. 204 of\n",
    "        J. Lim and A. Oppenheim, *All-Pole Modeling of Degraded Speech,*\n",
    "        IEEE Transactions on Acoustics, Speech, and Signal Processing 26.3\n",
    "        (1978): 197-210.\n",
    "    Namely solving for :math:`g^2` such that the following expression is\n",
    "    satisfied:\n",
    "    .. math::\n",
    "        \\dfrac{N}{2\\pi} \\int_{-\\pi}^{\\pi} \\dfrac{g^2}{\\\\left \\| 1 - \\sum_{k=1}^p a_k \\cdot e^{-jk\\omega} \\\\right \\|^2} d\\omega = \\sum_{n=0}^{N-1} y^2(n) - N\\cdot\\sigma_d^2,\n",
    "    where :math:`N` is the number of noisy samples :math:`y`, :math:`a_k`\n",
    "    are the :math:`p` LPC coefficients, and :math:`\\sigma_d^2` is the\n",
    "    noise variance.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : numpy array\n",
    "        LPC coefficients.\n",
    "    noise_psd : float or numpy array\n",
    "        Noise variance if white noise, numpy array otherwise.\n",
    "    y : numpy array\n",
    "        Noisy time domain samples.\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Squared gain.\n",
    "    \"\"\"\n",
    "\n",
    "    p = len(a)\n",
    "    def _lpc_all_pole(omega):\n",
    "        k = np.arange(p) + 1\n",
    "        return 1 / np.abs(1 - np.dot(a, np.exp(-1j * k * omega))) ** 2\n",
    "\n",
    "    N = len(y)\n",
    "\n",
    "    # right hand side of expression\n",
    "    if np.isscalar(noise_psd):   # white noise, i.e. flat spectrum\n",
    "        rhs = np.sum(y**2) - N * noise_psd\n",
    "    else:\n",
    "        rhs = np.sum(y**2) - np.sum(noise_psd)\n",
    "\n",
    "    # estimate integral\n",
    "    d_omega = 2 * np.pi / 1000\n",
    "    omega_vals = np.arange(-np.pi, np.pi, d_omega)\n",
    "    vec_integrand = np.vectorize(_lpc_all_pole)\n",
    "    integral = integrate.trapz(vec_integrand(omega_vals), omega_vals)\n",
    "    return rhs * 2 * np.pi / N / integral\n",
    "\n",
    "\n",
    "def compute_wiener_filter(speech_psd, noise_psd):\n",
    "    \"\"\"\n",
    "    Compute Wiener filter in the frequency domain.\n",
    "    Parameters\n",
    "    ----------\n",
    "    speech_psd : numpy array\n",
    "        Speech power spectral density.\n",
    "    noise_psd : float or numpy array\n",
    "        Noise variance if white noise, numpy array otherwise.\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array\n",
    "        Frequency domain filter, computed at the same frequency values as\n",
    "        `speech_psd`.\n",
    "    \"\"\"\n",
    "\n",
    "    return speech_psd / (speech_psd + noise_psd)\n",
    "\n",
    "\n",
    "def apply_iterative_wiener(noisy_signal, frame_len=512, lpc_order=20,\n",
    "                           iterations=2, alpha=0.8, thresh=0.01):\n",
    "    \"\"\"\n",
    "    One-shot function to apply iterative Wiener filtering for denoising.\n",
    "    Parameters\n",
    "    ----------\n",
    "    noisy_signal : numpy array\n",
    "        Real signal in time domain.\n",
    "    frame_len : int\n",
    "        Frame length in samples. 50% overlap is used with hanning window.\n",
    "    lpc_order : int\n",
    "        Number of LPC coefficients to compute\n",
    "    iterations : int\n",
    "        How many iterations to perform in updating the Wiener filter for each\n",
    "        signal frame.\n",
    "    alpha : int\n",
    "        Smoothing factor within [0,1] for updating noise level. Closer to `1`\n",
    "        gives more weight to the previous noise level, while closer to `0`\n",
    "        gives more weight to the current frame's level. Closer to `0` can track\n",
    "        more rapid changes in the noise level. However, if a speech frame is\n",
    "        incorrectly identified as noise, you can end up removing desired\n",
    "        speech.\n",
    "    thresh : float\n",
    "        Threshold to distinguish between (signal+noise) and (noise) frames. A\n",
    "        high value will classify more frames as noise but might remove desired\n",
    "        signal!\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array\n",
    "        Enhanced/denoised signal.\n",
    "    \"\"\"\n",
    "\n",
    "    from pyroomacoustics import hann\n",
    "    from pyroomacoustics.transform import STFT\n",
    "\n",
    "    hop = frame_len // 2\n",
    "    window = hann(frame_len, flag='asymmetric', length='full')\n",
    "    stft = STFT(frame_len, hop=hop, analysis_window=window, streaming=True)\n",
    "    scnr = IterativeWiener(frame_len, lpc_order, iterations, alpha, thresh)\n",
    "\n",
    "    processed_audio = np.zeros(noisy_signal.shape)\n",
    "    n = 0\n",
    "    while noisy_signal.shape[0] - n >= hop:\n",
    "        # SCNR in frequency domain\n",
    "        stft.analysis(noisy_signal[n:(n + hop), ])\n",
    "        X = scnr.compute_filtered_output(current_frame=stft.fft_in_buffer,\n",
    "                                         frame_dft=stft.X)\n",
    "\n",
    "        # back to time domain\n",
    "        processed_audio[n:n + hop, ] = stft.synthesis(X)\n",
    "\n",
    "        # update step\n",
    "        n += hop\n",
    "\n",
    "    return processed_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filterd_signal = apply_spectral_sub(noisy_signal)\n",
    "wavfile.write(filtered_fp, fs, filterd_signal.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IterativeWiener' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-23ee1dd61159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiltered_signal_iw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_iterative_wiener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_iw_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterd_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-9ac0c0b06498>\u001b[0m in \u001b[0;36mapply_iterative_wiener\u001b[0;34m(noisy_signal, frame_len, lpc_order, iterations, alpha, thresh)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhann\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'asymmetric'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'full'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mstft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTFT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalysis_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreaming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mscnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIterativeWiener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlpc_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprocessed_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IterativeWiener' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_signal_iw = apply_iterative_wiener(noisy_signal)\n",
    "wavfile.write(filtered_iw_fp, fs, filterd_signal.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
